{"cells":[{"cell_type":"markdown","id":"5e73fbeb","metadata":{"id":"5e73fbeb"},"source":["# Lab 3: Hierarchical and density-based clustering\n","\n","<a target=\"_blank\" href=\"https://colab.research.google.com/github/drchadvidden/courseMaterials/blob/main/UnsupervisedLearning/Labs/Lab%202/Lab_2.ipynb\">\n","<img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n","</a>"]},{"cell_type":"markdown","source":["# Lab Instructions\n","\n","Run each of the coding cells. For tutorial example cells, understand the commands and check that the outputs make sense. For exercise cells, write your own code where indicated to generate the correct output. Give text explanations where indicated.\n","\n","### Submission:\n","Complete the following notebook in order. Once done, save the notebook, print the file as a .pdf, and upload the resulting file to the Canvas course assignment.\n","\n","### Rubric:\n","15 total points, 5 points to running tutorial example cells and saving outputs, 10 points for completing exercises.\n","\n","### Deadline:\n","Tuesday at midnight after the lab is assigned."],"metadata":{"id":"J5awbmuT7Ott"},"id":"J5awbmuT7Ott"},{"cell_type":"markdown","source":["# Tutorial: Hierarchical Clustering"],"metadata":{"id":"MZOO-cKL83Qf"},"id":"MZOO-cKL83Qf"},{"cell_type":"markdown","source":["## Hierarchical Clustering of Penguins\n","\n","In this tutorial, we perform hierarchical clustering on the penguins dataset using several numeric measurements: bill length, bill depth, flipper length, and body mass.\n","\n","Hierarchical clustering creates a tree-like structure (dendrogram) that shows how observations are merged into clusters step by step. The y-axis of the dendrogram represents the distance at which clusters are fused, and the leaves correspond to individual observations.\n","\n","Before clustering, we standardize the features so that differences in scale (e.g., body mass vs. bill length) do not dominate the clustering. We then compute the linkage using the complete linkage method, which defines the distance between clusters as the maximum distance between points in the two clusters. Finally, we plot the dendrogram to visualize the hierarchical structure of the penguins data.\n","\n","Below is the Python code to perform these steps."],"metadata":{"id":"RIshPdeyOJCR"},"id":"RIshPdeyOJCR"},{"cell_type":"code","source":["# --- Imports ---\n","import seaborn as sns\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from scipy.cluster.hierarchy import dendrogram, linkage\n","from sklearn.preprocessing import StandardScaler\n","\n","# --- Load dataset, more details here https://seaborn.pydata.org/generated/seaborn.load_dataset.html ---\n","penguins = sns.load_dataset('penguins')\n","\n","# --- Select numeric features and drop missing values ---\n","numeric_cols = ['bill_length_mm', 'bill_depth_mm', 'flipper_length_mm', 'body_mass_g']\n","data = penguins[numeric_cols].dropna()\n","\n","# --- Standardize features ---\n","scaler = StandardScaler()\n","X_scaled = scaler.fit_transform(data)\n","\n","# --- Perform hierarchical clustering ---\n","Z = linkage(X_scaled, method='complete')  # method can be 'single', 'complete', 'average', 'ward'\n","\n","# --- Plot dendrogram ---\n","plt.figure(figsize=(10, 5))\n","dendrogram(Z, labels=data.index, color_threshold=5)\n","plt.title(\"Hierarchical Clustering Dendrogram (Penguins)\")\n","plt.xlabel(\"Observation Index\")\n","plt.ylabel(\"Distance\")\n","plt.show()\n"],"metadata":{"id":"sUQaWyI9SV1G"},"id":"sUQaWyI9SV1G","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## How the Dendrogram Cut Works\n","\n","The dendrogram plotted above shows the full hierarchical clustering, from individual observations at the leaves to a single cluster at the top.\n","\n","Although we did not explicitly specify a cut, scipy’s dendrogram() function automatically colors branches to make clusters easier to see. Try changing the \"color_threshold=5\" in this command.\n","\n","Branches that merge below this threshold are colored differently. In the penguins dendrogram, this produces three main colored branches, giving a visual suggestion of three clusters.\n","\n","Important: This coloring is purely for visualization. The dendrogram itself still represents the full hierarchy; no cluster labels have been assigned yet.\n","To actually assign clusters, we can use scipy.cluster.hierarchy.fcluster() with either a distance threshold or a target number of clusters.\n","\n","Next, decide the dedrogram cut location visually from above and assign cluster memberships to our data. This can be visualized in 2D for any pair of numeric features."],"metadata":{"id":"ol92KsDvSL0c"},"id":"ol92KsDvSL0c"},{"cell_type":"code","source":["from scipy.cluster.hierarchy import fcluster\n","import matplotlib.pyplot as plt\n","\n","# --- Assign clusters from linkage matrix Z ---\n","# Here we choose 3 clusters\n","clusters = fcluster(Z, 3, criterion='maxclust')\n","\n","# Add cluster labels to the data\n","data_plot = data.copy()\n","data_plot['cluster'] = clusters\n","\n","# --- Plot clusters: flipper_length_mm vs bill_length_mm ---\n","plt.figure(figsize=(8,6))\n","for c in sorted(data_plot['cluster'].unique()):\n","    subset = data_plot[data_plot['cluster'] == c]\n","    plt.scatter(subset['flipper_length_mm'], subset['bill_length_mm'], label=f'Cluster {c}', s=50)\n","\n","plt.xlabel('Flipper Length (mm)')\n","plt.ylabel('Bill Length (mm)')\n","plt.title('Hierarchical Clustering of Penguins (3 Clusters)')\n","plt.legend()\n","plt.grid(True)\n","plt.show()\n"],"metadata":{"id":"q5b710nbTgdc"},"id":"q5b710nbTgdc","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Cluster assignment vs penguin species\n","\n","Because we actually know the penguin species name in our dataset, we can compare our clustering findings to a ground truth as below. I wonder why some Chinstrap penguins were clustered with Adelie penguins?"],"metadata":{"id":"BO_WarinVCFA"},"id":"BO_WarinVCFA"},{"cell_type":"code","source":["# --- Add cluster labels and species ---\n","data_plot = data.copy()\n","data_plot['cluster'] = clusters\n","data_plot['species'] = penguins.loc[data.index, 'species']\n","\n","# --- Confusion matrix: cluster number vs species ---\n","confusion_matrix = pd.crosstab(data_plot['cluster'], data_plot['species'])\n","print(confusion_matrix)\n"],"metadata":{"id":"xzpZ0omTT_zP"},"id":"xzpZ0omTT_zP","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Evaluating the Dendrogram with Cophenetic Correlation\n","\n","The cophenetic correlation coefficient (CCC) measures how well a dendrogram preserves the original pairwise distances between observations.\n","\n","A higher CCC (closer to 1) indicates that the dendrogram accurately reflects the true distances in the data.\n","\n","A lower CCC suggests that the hierarchical clustering distorts the distances more.\n","\n","This metric is useful for assessing different linkage methods or confirming that the dendrogram is a faithful representation of the data before deciding where to cut it.\n","\n","Below is how to compute the CCC for our penguins hierarchical clustering."],"metadata":{"id":"nZjdjcURVWVl"},"id":"nZjdjcURVWVl"},{"cell_type":"code","source":["from scipy.cluster.hierarchy import cophenet\n","\n","c, coph_dists = cophenet(Z, pdist(X_scaled))\n","print(f\"Cophenetic Correlation Coefficient: {c:.3f}\")"],"metadata":{"id":"HKcZYALyQfyn"},"id":"HKcZYALyQfyn","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Tutorial: DBSCAN"],"metadata":{"id":"JhVroSAGWYTI"},"id":"JhVroSAGWYTI"},{"cell_type":"markdown","source":["## Density-Based Clustering (DBSCAN) with Penguins\n","\n","In this tutorial, we will use DBSCAN (Density-Based Spatial Clustering of Applications with Noise) to cluster penguin observations based on numeric features: bill length, bill depth, flipper length, and body mass.\n","\n","DBSCAN is a density-based clustering algorithm. Its key properties:\n","\n","- Groups together points that are densely packed.\n","\n","- Labels points in sparse regions as noise (outliers).\n","\n","- Can detect clusters of arbitrary shapes, unlike k-means or hierarchical clustering.\n","\n","We will standardize the features, fit DBSCAN, and visualize the clusters using two key numeric features: flipper length and bill length. Finally, we’ll compare the DBSCAN clusters to the actual penguin species.\n","\n","To fir DBSCAN, we choose two key parameters:\n","\n","- eps: maximum distance between two points to be considered neighbors\n","\n","- min_samples: minimum number of points in a neighborhood for a point to be considered a core point"],"metadata":{"id":"iC2rDgiViy2Z"},"id":"iC2rDgiViy2Z"},{"cell_type":"code","source":["# --- Imports ---\n","import seaborn as sns\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.cluster import DBSCAN\n","\n","# --- Load dataset ---\n","penguins = sns.load_dataset('penguins')\n","\n","# --- Select numeric features and drop missing values ---\n","numeric_cols = ['bill_length_mm', 'bill_depth_mm', 'flipper_length_mm', 'body_mass_g']\n","data = penguins[numeric_cols].dropna()\n","\n","# --- Standardize features ---\n","scaler = StandardScaler()\n","X_scaled = scaler.fit_transform(data)\n","\n","# --- Fit DBSCAN ---\n","db = DBSCAN(eps=0.8, min_samples=5)  # tweak eps for better clusters\n","db.fit(X_scaled)\n","\n","# --- Cluster labels ---\n","labels = db.labels_\n","data_plot = data.copy()\n","data_plot['cluster'] = labels\n","\n","# Number of clusters (excluding noise)\n","n_clusters = len(set(labels)) - (1 if -1 in labels else 0)\n","n_noise = list(labels).count(-1)\n","print(f\"Estimated number of clusters: {n_clusters}\")\n","print(f\"Number of noise points: {n_noise}\")\n"],"metadata":{"id":"qWj9dhX7hitY"},"id":"qWj9dhX7hitY","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Visualizing DBSCAN Clusters\n","\n","We will plot flipper length (x-axis) vs bill length (y-axis) and color points by their DBSCAN cluster. Noise points (-1) will be colored gray."],"metadata":{"id":"b6ixp4B_dajw"},"id":"b6ixp4B_dajw"},{"cell_type":"code","source":["plt.figure(figsize=(8,6))\n","\n","# Assign colors: noise=-1 is gray\n","colors = ['gray', 'red', 'blue', 'green', 'orange', 'purple', 'cyan']\n","for cluster_id in set(labels):\n","    subset = data_plot[data_plot['cluster'] == cluster_id]\n","    color = colors[cluster_id + 1] if cluster_id != -1 else 'gray'\n","    label = 'Noise' if cluster_id == -1 else f'Cluster {cluster_id}'\n","    plt.scatter(subset['flipper_length_mm'], subset['bill_length_mm'],\n","                label=label, s=50, alpha=0.7, color=color)\n","\n","plt.xlabel('Flipper Length (mm)')\n","plt.ylabel('Bill Length (mm)')\n","plt.title('DBSCAN Clustering of Penguins')\n","plt.legend()\n","plt.grid(True)\n","plt.show()\n"],"metadata":{"id":"ODEqcVXXdbrN"},"id":"ODEqcVXXdbrN","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Again, we can compare the cluster assignment to the true cluster solution. You can tweak eps and min_samples to see how cluster assignments change."],"metadata":{"id":"Xe4AV3Khi5Yp"},"id":"Xe4AV3Khi5Yp"},{"cell_type":"code","source":["# --- Add species names ---\n","data_plot['species'] = penguins.loc[data.index, 'species']\n","\n","# --- Confusion matrix: cluster vs species ---\n","confusion_matrix = pd.crosstab(data_plot['cluster'], data_plot['species'])\n","print(confusion_matrix)"],"metadata":{"id":"X4BLcIfcjJtj"},"id":"X4BLcIfcjJtj","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Choosing DBSCAN Parameters (eps and min_samples)\n","\n","DBSCAN requires two parameters:\n","\n","- eps — the maximum distance between points to be considered neighbors.\n","\n","- min_samples — the minimum number of points in a neighborhood for a point to be considered a core point.\n","\n","To select a good eps:\n","\n","- Set min_samples based on the dataset size and dimensionality (a common rule of thumb is number of features + 1).\n","\n","- Compute the distance to the k-th nearest neighbor for each point (k = min_samples).\n","\n","- Plot these distances in ascending order (k-distance graph) and look for a “knee” or sharp bend — this indicates a natural choice for eps.\n","\n","Once eps and min_samples are chosen, DBSCAN can automatically identify clusters and label outliers (noise)."],"metadata":{"id":"3UOlOP8ieLhv"},"id":"3UOlOP8ieLhv"},{"cell_type":"code","source":["from sklearn.neighbors import NearestNeighbors\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","k = 5  # same as min_samples\n","neighbors = NearestNeighbors(n_neighbors=k)\n","neighbors_fit = neighbors.fit(X_scaled)\n","distances, indices = neighbors_fit.kneighbors(X_scaled)\n","\n","# Take the k-th nearest neighbor distance\n","k_distances = np.sort(distances[:, k-1])\n","\n","plt.figure(figsize=(8,5))\n","plt.plot(k_distances)\n","plt.ylabel(f\"{k}-th Nearest Neighbor Distance\")\n","plt.xlabel(\"Points sorted by distance\")\n","plt.title(\"k-distance Graph for DBSCAN\")\n","plt.grid(True)\n","plt.show()\n"],"metadata":{"id":"5Rfy73lVeMJH"},"id":"5Rfy73lVeMJH","execution_count":null,"outputs":[]},{"cell_type":"markdown","id":"bc7e71b4","metadata":{"id":"bc7e71b4"},"source":["# Exercise(s): Hierarchical and density-based clustering\n","\n","\n","\n"]},{"cell_type":"markdown","source":["## Exercise 1: Exploring Different Linkage Methods\n","\n","In this exercise, you will redo the hierarchical clustering on the penguins dataset using linkage methods other than complete linkage, and explore how the choice of linkage affects the clusters.\n","\n","### Tasks:\n","\n","1. Using the same numeric features (bill_length_mm, bill_depth_mm, flipper_length_mm, body_mass_g), standardize the data as in the tutorial.\n","\n","2. Perform hierarchical clustering using the following linkage methods:\n","- Single linkage\n","- Average linkage\n","- Ward linkage\n","\n","3. For each linkage method:\n","- Plot the dendrogram.\n","- Assign clusters using 3 clusters (as in the tutorial) with fcluster().\n","- Plot the clusters using flipper length (x-axis) and bill length (y-axis).\n","\n","4. For each linkage method:\n","\n","- Identify the height at which the final three clusters merge into two.\n","- Compare these heights across linkage methods.\n","- Briefly explain what this suggests about cluster separation under each method.\n","\n","5. Compare the cluster assignments to penguin species:\n","\n","- Create a confusion matrix (cluster vs species) for each linkage method.\n","- Briefly describe how the cluster assignments differ between linkage methods.\n","- Compute the cophenetic correlation coefficient (CCC) for all 4 linkage methods and explain which is the best fit. Does the best CCC clustering relative to species label?"],"metadata":{"id":"c6Jjkpv7_V0V"},"id":"c6Jjkpv7_V0V"},{"cell_type":"code","source":["# Write your code for the exercise 2 here!"],"metadata":{"id":"JfKK2B6tAsyP"},"id":"JfKK2B6tAsyP","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Explain your findings here:\n","\n","\n"],"metadata":{"id":"j9QclKNiAwKr"},"id":"j9QclKNiAwKr"},{"cell_type":"markdown","source":["## Exercise 2: Analyzing DBSCAN Behavior on Penguins\n","\n","In this exercise, you will investigate how DBSCAN behaves under different parameter choices and compare its structure to hierarchical clustering.\n","\n","You may reuse the standardized dataset from the tutorial.\n","\n","### Tasks:\n","\n","Using min_samples = 5:\n","\n","1. Run DBSCAN with three different values of eps:\n","- One clearly too small\n","- One near the knee from the k-distance plot\n","- One clearly too large\n","- Visualize your results and compare to the true species\n","\n","2. For each choice of eps, report:\n","- Number of clusters found\n","- Number of noise points\n","\n","3. Briefly explain:\n","- What happens when eps is too small?\n","- What happens when eps is too large?\n","- Why does this occur in terms of density connectivity?\n","\n","4. For your best DBSCAN model:\n","- How many core points are there?\n","- How many border points?\n","- How many noise points?\n","\n","5. Choose one cluster and:\n","- Describe the geometric difference between its core and border points.\n","- Explain why border points might represent biologically ambiguous penguins (for example, overlap between Adelie and Chinstrap).\n","\n","6. Pairwise feature visualization\n","- Create a pairwise scatterplot matrix of the four numeric variables, coloring points by their DBSCAN cluster label.\n","- Use seaborn’s pairplot() function.\n","- Color points using the hue argument.\n","- Restrict the plot to the four numeric columns.\n","- Hint: sns.pairplot(data_plot, hue='cluster', vars=numeric_cols)\n","- Explain your findings.\n","\n","7. Compute the mean of each numeric feature within each DBSCAN cluster and explain your findings.\n"],"metadata":{"id":"yjA8qBgmh76t"},"id":"yjA8qBgmh76t"},{"cell_type":"code","source":["# Write your code for the exercise 1 here!"],"metadata":{"id":"vXoiwichiCwW"},"execution_count":null,"outputs":[],"id":"vXoiwichiCwW"},{"cell_type":"markdown","source":["### Explain your findings here:\n","\n","\n"],"metadata":{"id":"Dj0WsaKViAJN"},"id":"Dj0WsaKViAJN"},{"cell_type":"markdown","source":["## Exercise 3: Comparing Clustering Methods on Customer Data\n","\n","You previously analyzed this dataset using k-means. Now apply:\n","- Hierarchical clustering\n","- DBSCAN\n","\n","Your goal is to determine which method produces the most meaningful customer segmentation.\n","\n","### Tasks:\n","\n","1. Apply hierarchical clustering (choose an appropriate linkage method and number of clusters).\n","\n","2. Apply DBSCAN (choose reasonable eps and min_samples).\n","\n","3. Compare both results to your previous k-means solution of Lab 2.\n","\n","### Analyze\n","\n","How many clusters does each method produce?\n","\n","Do the cluster sizes differ substantially?\n","\n","Does DBSCAN identify noise or outliers?\n","\n","Which method produces the most interpretable customer segments?\n","\n","### Conclusion\n","\n","In 4–6 sentences, argue which clustering method is “best” for this dataset and justify your reasoning.\n"],"metadata":{"id":"W0v7dgbFmBSG"},"id":"W0v7dgbFmBSG"},{"cell_type":"code","source":["# Write your code for the exercise 3 here!\n","\n","import pandas as pd\n","\n","# this file is also hosted on Kaggle: https://www.kaggle.com/datasets/vjchoudhary7/customer-segmentation-tutorial-in-python\n","url = 'https://gist.githubusercontent.com/pravalliyaram/5c05f43d2351249927b8a3f3cc3e5ecf/raw/8bd6144a87988213693754baaa13fb204933282d/Mall_Customers.csv'\n","df = pd.read_csv(url)\n","\n","print(df.head())\n","print(df.info())\n","print(df.describe())\n","print(df[\"Gender\"].value_counts())"],"metadata":{"id":"RiGiFbnmmGBq"},"execution_count":null,"outputs":[],"id":"RiGiFbnmmGBq"},{"cell_type":"markdown","source":["### Explain your findings here:\n","\n","\n"],"metadata":{"id":"H61d7Q48mKzN"},"id":"H61d7Q48mKzN"}],"metadata":{"jupytext":{"cell_metadata_filter":"-all","main_language":"python","notebook_metadata_filter":"-all"},"language_info":{"name":"python"},"colab":{"provenance":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"}},"nbformat":4,"nbformat_minor":5}